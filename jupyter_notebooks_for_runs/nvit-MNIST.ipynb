{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3027540,"status":"ok","timestamp":1733730537748,"user":{"displayName":"Pratyush Kumar","userId":"15062819489477391288"},"user_tz":300},"id":"2v9-mnCmEgub"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) =\u003e {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() =\u003e {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() =\u003e reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data =\u003e {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W\u0026B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]}],"source":["import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import datasets, transforms\n","import wandb\n","import os\n","import numpy as np\n","import torch.nn.functional as F\n","from einops import rearrange\n","from einops.layers.torch import Rearrange\n","import torch.nn.utils.parametrize as parametrize\n","import math\n","\n","# Set random seeds for reproducibility\n","torch.manual_seed(42)\n","torch.cuda.manual_seed_all(42)\n","np.random.seed(42)\n","\n","# Helper functions\n","def exists(v):\n","    return v is not None\n","\n","def default(v, d):\n","    return v if exists(v) else d\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","def divisible_by(numer, denom):\n","    return (numer % denom) == 0\n","\n","def l2norm(t, dim=-1):\n","    return F.normalize(t, dim=dim, p=2)\n","\n","# For use with parametrize\n","class L2Norm(nn.Module):\n","    def __init__(self, dim=-1):\n","        super().__init__()\n","        self.dim = dim\n","\n","    def forward(self, t):\n","        return l2norm(t, dim=self.dim)\n","\n","class NormLinear(nn.Module):\n","    def __init__(self, dim, dim_out, norm_dim_in=True):\n","        super().__init__()\n","        self.linear = nn.Linear(dim, dim_out, bias=False)\n","\n","        parametrize.register_parametrization(\n","            self.linear,\n","            'weight',\n","            L2Norm(dim=-1 if norm_dim_in else 0)\n","        )\n","\n","    @property\n","    def weight(self):\n","        return self.linear.weight\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","# Scaled dot product attention function\n","def scaled_dot_product_attention(q, k, v, dropout_p=0., training=True):\n","    d_k = q.size(-1)\n","    attn_weights = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n","    attn_weights = F.softmax(attn_weights, dim=-1)\n","    if training and dropout_p \u003e 0.0:\n","        attn_weights = F.dropout(attn_weights, p=dropout_p)\n","    output = torch.matmul(attn_weights, v)\n","    return output\n","\n","# Attention and FeedForward classes\n","class Attention(nn.Module):\n","    def __init__(self, dim, *, dim_head=64, heads=8, dropout=0.):\n","        super().__init__()\n","        dim_inner = dim_head * heads\n","        self.to_q = NormLinear(dim, dim_inner)\n","        self.to_k = NormLinear(dim, dim_inner)\n","        self.to_v = NormLinear(dim, dim_inner)\n","\n","        self.dropout = dropout\n","\n","        self.q_scale = nn.Parameter(torch.ones(heads, 1, dim_head) * (dim_head ** 0.25))\n","        self.k_scale = nn.Parameter(torch.ones(heads, 1, dim_head) * (dim_head ** 0.25))\n","\n","        self.split_heads = Rearrange('b n (h d) -\u003e b h n d', h=heads)\n","        self.merge_heads = Rearrange('b h n d -\u003e b n (h d)')\n","\n","        self.to_out = NormLinear(dim_inner, dim, norm_dim_in=False)\n","\n","    def forward(self, x):\n","        q, k, v = self.to_q(x), self.to_k(x), self.to_v(x)\n","\n","        q, k, v = map(self.split_heads, (q, k, v))\n","\n","        # Query key rmsnorm\n","        q, k = map(l2norm, (q, k))\n","\n","        q = q * self.q_scale\n","        k = k * self.k_scale\n","\n","        out = scaled_dot_product_attention(\n","            q, k, v,\n","            dropout_p=self.dropout,\n","            training=self.training\n","        )\n","\n","        out = self.merge_heads(out)\n","        return self.to_out(out)\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, *, dim_inner, dropout=0.):\n","        super().__init__()\n","        dim_inner = int(dim_inner * 2 / 3)\n","\n","        self.dim = dim\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.to_hidden = NormLinear(dim, dim_inner)\n","        self.to_gate = NormLinear(dim, dim_inner)\n","\n","        self.hidden_scale = nn.Parameter(torch.ones(dim_inner))\n","        self.gate_scale = nn.Parameter(torch.ones(dim_inner))\n","\n","        self.to_out = NormLinear(dim_inner, dim, norm_dim_in=False)\n","\n","    def forward(self, x):\n","        hidden, gate = self.to_hidden(x), self.to_gate(x)\n","\n","        hidden = hidden * self.hidden_scale\n","        gate = gate * self.gate_scale * (self.dim ** 0.5)\n","\n","        hidden = F.silu(gate) * hidden\n","\n","        hidden = self.dropout(hidden)\n","        return self.to_out(hidden)\n","\n","# nViT base class\n","class nViT(nn.Module):\n","    def __init__(\n","        self,\n","        *,\n","        image_size,\n","        patch_size,\n","        num_classes,\n","        dim,\n","        depth,\n","        heads,\n","        mlp_dim,\n","        dropout=0.,\n","        channels=1,  # MNIST is grayscale\n","        dim_head=64,\n","        residual_lerp_scale_init=None\n","    ):\n","        super().__init__()\n","        image_height, image_width = pair(image_size)\n","\n","        assert divisible_by(image_height, patch_size) and divisible_by(image_width, patch_size), 'Image dimensions must be divisible by the patch size.'\n","\n","        patch_height_dim, patch_width_dim = (image_height // patch_size), (image_width // patch_size)\n","        patch_dim = channels * (patch_size ** 2)\n","        num_patches = patch_height_dim * patch_width_dim\n","\n","        self.channels = channels\n","        self.patch_size = patch_size\n","        self.num_patches = num_patches\n","        self.image_size = image_size\n","\n","        self.to_patch_embedding = nn.Sequential(\n","            Rearrange('b c (h p1) (w p2) -\u003e b (h w) (c p1 p2)', p1=patch_size, p2=patch_size),\n","            NormLinear(patch_dim, dim, norm_dim_in=False),\n","        )\n","\n","        self.abs_pos_emb = NormLinear(dim, num_patches)\n","\n","        residual_lerp_scale_init = default(residual_lerp_scale_init, 1. / depth)\n","\n","        self.dim = dim\n","        self.scale = dim ** 0.5\n","\n","        self.layers = nn.ModuleList([])\n","        self.residual_lerp_scales = nn.ModuleList([])\n","\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                Attention(dim, dim_head=dim_head, heads=heads, dropout=dropout),\n","                FeedForward(dim, dim_inner=mlp_dim, dropout=dropout),\n","            ]))\n","\n","            self.residual_lerp_scales.append(nn.ParameterList([\n","                nn.Parameter(torch.ones(dim) * residual_lerp_scale_init / self.scale),\n","                nn.Parameter(torch.ones(dim) * residual_lerp_scale_init / self.scale),\n","            ]))\n","\n","        # Classification head\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        device = x.device\n","\n","        tokens = self.to_patch_embedding(x)\n","\n","        seq_len = tokens.shape[-2]\n","        pos_emb = self.abs_pos_emb.weight[torch.arange(seq_len, device=device)]\n","\n","        tokens = l2norm(tokens + pos_emb)\n","\n","        for (attn, ff), residual_scales in zip(self.layers, self.residual_lerp_scales):\n","            attn_alpha, ff_alpha = residual_scales\n","\n","            attn_out = l2norm(attn(tokens))\n","            tokens = l2norm(tokens.lerp(attn_out, attn_alpha * self.scale))\n","\n","            ff_out = l2norm(ff(tokens))\n","            tokens = l2norm(tokens.lerp(ff_out, ff_alpha * self.scale))\n","\n","        # Classification token (mean pooling)\n","        tokens = tokens.mean(dim=1)\n","        logits = self.mlp_head(tokens)\n","        return logits\n","\n","def main():\n","    # Initialize wandb\n","    wandb.init(project='nvit-mnist', config={\n","        'model': 'nViT',\n","        'dataset': 'MNIST',\n","        'epochs': 100,\n","        'batch_size': 128,\n","        'learning_rate': 3e-4,\n","        'weight_decay': 1e-4,\n","        'image_size': 28,          # MNIST image size\n","        'patch_size': 4,           # Patch size for MNIST (28 / 4 = 7 patches per dimension)\n","        'dim': 384,                # Model dimension\n","        'depth': 6,                # Transformer depth\n","        'heads': 6,                # Number of heads\n","        'mlp_dim': 384 * 4,        # MLP hidden dimension\n","        'dropout': 0.1,\n","        'num_classes': 10,\n","        'dim_head': 64\n","    })\n","    config = wandb.config\n","\n","    # Set device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Data transforms\n","    transform_train = transforms.Compose([\n","        transforms.RandomCrop(config.image_size, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,)),  # MNIST mean and std\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,)),\n","    ])\n","\n","    # Load MNIST dataset\n","    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n","    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n","\n","    # Initialize model\n","    model = nViT(\n","        image_size=config.image_size,\n","        patch_size=config.patch_size,\n","        num_classes=config.num_classes,\n","        dim=config.dim,\n","        depth=config.depth,\n","        heads=config.heads,\n","        mlp_dim=config.mlp_dim,\n","        dropout=config.dropout,\n","        channels=1,               # MNIST is grayscale\n","        dim_head=config.dim_head\n","    ).to(device)\n","\n","    # Loss function and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n","\n","    # Training loop\n","    best_acc = 0.0\n","    for epoch in range(config.epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        for batch_idx, (inputs, targets) in enumerate(train_loader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            if batch_idx % 100 == 0:\n","                wandb.log({\n","                    'train_loss': running_loss / (batch_idx + 1),\n","                    'train_acc': 100. * correct / total,\n","                    'learning_rate': optimizer.param_groups[0]['lr']\n","                })\n","\n","        # Validation\n","        model.eval()\n","        test_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, targets in test_loader:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","\n","                test_loss += loss.item()\n","                _, predicted = outputs.max(1)\n","                total += targets.size(0)\n","                correct += predicted.eq(targets).sum().item()\n","\n","        acc = 100. * correct / total\n","        avg_test_loss = test_loss / len(test_loader)\n","        wandb.log({\n","            'test_loss': avg_test_loss,\n","            'test_acc': acc,\n","            'epoch': epoch + 1\n","        })\n","\n","        print(f\"Epoch {epoch + 1}/{config.epochs} - \"\n","              f\"Train Loss: {running_loss / len(train_loader):.4f}, \"\n","              f\"Train Acc: {100. * correct / total:.2f}%, \"\n","              f\"Test Loss: {avg_test_loss:.4f}, \"\n","              f\"Test Acc: {acc:.2f}%\")\n","\n","        # Save best model\n","        if acc \u003e best_acc:\n","            best_acc = acc\n","            torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'best_model.pth'))\n","\n","        scheduler.step()\n","\n","    print(f\"Training completed. Best Test Accuracy: {best_acc:.2f}%\")\n","    wandb.finish()\n","\n","if __name__ == '__main__':\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sU-i_fwEjIe"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN5CUfxfgQTTOKbaSQ4QPE0","gpuType":"L4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2219924b69444ad9addef7ea47755028":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_abbba2f2642f4c518f535a78c66d73ee","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9e853d2c29b4b3e8eea1d58ce6dfbb6","value":1}},"abbba2f2642f4c518f535a78c66d73ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba5fe96d25d34960ae57eed2ca8d1001":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be57b8b9af2c40d48eb00577dd1061d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd4098e93863407fb901ccba66f708ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9e853d2c29b4b3e8eea1d58ce6dfbb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed2dab9faedd4903b9258de9014b52a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_fbe20f3ade10484baa1d7986b6f825c3","IPY_MODEL_2219924b69444ad9addef7ea47755028"],"layout":"IPY_MODEL_be57b8b9af2c40d48eb00577dd1061d3"}},"fbe20f3ade10484baa1d7986b6f825c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba5fe96d25d34960ae57eed2ca8d1001","placeholder":"â€‹","style":"IPY_MODEL_cd4098e93863407fb901ccba66f708ee","value":"0.023 MB of 0.023 MB uploaded\r"}}}}},"nbformat":4,"nbformat_minor":0}